# How to do a Data Science Project (UCSB) 

Adapted from https://github.com/UCSB-dataScience-ProjectGroup/dataScience-UCSBProjectGroup-Syllabus

Once you start the process of a Data Science project you will quickly be introduced to the concept of *open-source* (if you haven't already). This concept was introduced to me through **R/Rstudio** and I quickly fell in love with *open-source*. Once you have learned the tools and have published a project, using **RStudio** or **Python**, you can publish to [inertia7](http://www.inertia7.com/) or your GitHub Repo, but you will realize that you have made your imprint unto this growing community where anyone can learn from you if they so choose to! 

Here I've provided a (non-exhaustive) list of *open-source* communities that provide resources at any skill level for people wanting to enter this field:

- [RBloggers](https://www.r-bloggers.com/)
- [Stack Overflow](http://stackoverflow.com/)
  - [Cross Validated](http://stats.stackexchange.com/)
- [Kaggle](https://www.kaggle.com/)

We can go on and on about resources, but regardless of how many resources we provide, people will still be left with an air of mystery as to what exactly a Data Science Project is. So the next section aims to dissect the process of doing a Data Science Project, and provide more resources at every step. 

## Getting the Data

We are assuming that for you to have gotten this far you have a basic understanding of some statistical tools/methods and are fairly knowledgeable with either **R**/**Python** as your tool for project building (granted we don't expect you to be experts on either but knowing how to manipulate data frames, conditional formatting, and data wrangling are a must to do projects).

This part of the project building can be daunting due to the over-abundance of data sets/raw data. 

This step requires more thought than one might think, and will ultimately be decided as to what your team is interested in. This can range from sports, video games, music, etc. If it exists there is data available for it. And if there isn't then you can be the first to collect data (more on this later!)

Now if you're a beginner we recommend using data sets that have are *open-source* and have been used before for Data Science projects. 

This can range from:
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.html) 
- https://www.kaggle.com/about/inclass/overview
- Data sets found in the **RStudio** base packages found here: http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html. 
- API Calls to certain websites like **Twitter**, **Reddit**, **Google Maps** to name a few.

A piece of advice when choosing a data set, when starting off, is to choose one that isn't to over the top. The best way to learn is to go through a simple data set and then expand what you learned unto more complicated data sets once you become familar with the process. For many of our projects in inertia7.com we chose data sets that were often used in our Statstical Classes and online resources, that we mentioned, to slowly build up our repertoire and skill set. 

Start small and build your way up

## Data Wrangling

This part varies from data set to data set. Once you have chosen your data set/collected your data, the next step is the process of cleaning the data known as *Data Wrangling*. If you have chosen a data set that has been abundantly used in statistical courses/Online Data Science resources you will find that you can easily reference other people's work when it comes to cleaning your data set(**Remember to Cite every source you use**). As well as finding justifications readily available for the transformations that were made.  

This step is crucial; often we take for granted the data sets we use, but one will find that data sets are often very messy and it is up to you to go through the process known as *Data wrangling*. 

## Data Visualization
Something many people take for granted is *Data visualization* when going about Data Science Projects. Known as **Exploratory Analysis**, visuals are an important factor of projects because it helps gain readers that are interested in what the data has to say in, usually people who don't have a strong data based background. As you progress on to more complicated projects the visualizations will take a back seat to the analystical aspect of your project, but if you're a beginner visualizations are a powerful tool to lure other beginners and a wide array of people into reading your project no matter how simple or trivial you might think it is. 

An example of this being a subreddit called [Dataisbeautiful](https://www.reddit.com/r/dataisbeautiful/) currenlty followed by 9,616,736 redditors. This subreddit focuses on simple visualizations of data collected by redditors. Many of these projects do not feature machine learning or advanced statistical inferences, but there's a reason it has so many followers. 

Many people who do not posess the data-driven background still love to learn about data presented to them in a way they can understand, and a visualization is just that. 

